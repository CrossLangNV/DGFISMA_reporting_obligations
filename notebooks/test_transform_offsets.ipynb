{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading AllenNLP predictor from /notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations/tests/test_files/models/bert_model/bert-base-srl-2019.06.17.tar.gz\n",
      "loading spacy model from /notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations/tests/test_files/models/spacy_model/spacy-textcat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "PATH=\"/notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations\"\n",
    "sys.path.append( os.path.join( PATH ) )\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import spacy\n",
    "\n",
    "BERT_PATH=os.path.join(  PATH, \"tests/test_files/models\", \"bert_model\", \"bert-base-srl-2019.06.17.tar.gz\" )\n",
    "SPACY_PATH=os.path.join( PATH, \"tests/test_files/models\", \"spacy_model\", \"spacy-textcat\" )\n",
    "\n",
    "#print( f\"loading AllenNLP predictor from {BERT_PATH}\" )\n",
    "#bert_model = Predictor.from_path( BERT_PATH, cuda_device=0 )\n",
    "\n",
    "#print( f\"loading spacy model from {SPACY_PATH}\" )\n",
    "#nlp=spacy.load( SPACY_PATH )\n",
    "\n",
    "#http://docs.allennlp.org/v0.9.0/api/allennlp.predictors.html\n",
    "from src.reporting_obligations import ReportingObligationsFinder\n",
    "\n",
    "reporting_obligations_finder = ReportingObligationsFinder(  BERT_PATH, SPACY_PATH, gpu=0  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in cassis \n",
    "#read in the json:\n",
    "import json\n",
    "import base64\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from typing import Generator, List\n",
    "\n",
    "from cassis.typesystem import load_typesystem\n",
    "from cassis.xmi import load_cas_from_xmi\n",
    "from cassis import Cas\n",
    "\n",
    "TEMPLATE_PATH=os.path.join( PATH, \"tests/test_files/templates/out.html.template\" )\n",
    "\n",
    "\n",
    "with open( os.path.join( PATH , \"tests/test_files/typesystems/typesystem.xml\" )  , 'rb') as f:\n",
    "    typesystem = load_typesystem(f)\n",
    "\n",
    "#with open( os.path.join( PATH, 'tests/test_files/response_json_paragraph_annotations/double_nested_list_response.json')) as json_file:\n",
    "#    response = json.load(json_file)\n",
    "\n",
    "#with open( os.path.join( PATH, 'tests/test_files/response_json_paragraph_annotations/small_nested_tables_response.json')) as json_file:\n",
    "#    response = json.load(json_file)\n",
    "    \n",
    "#with open( os.path.join( PATH, 'tests/test_files/response_json_paragraph_annotations/minus_lesser_of_response.json')) as json_file:\n",
    "#    response = json.load(json_file)  \n",
    "\n",
    "#with open( os.path.join( PATH, 'tests/test_files/testing_bug/32011D1208-input.json')) as json_file:\n",
    "#    response = json.load(json_file)  \n",
    "    \n",
    "#with open( os.path.join( PATH, 'tests/test_files/response_json_paragraph_annotations/32002R0063-input.xmi_outputPar_det.json')) as json_file:\n",
    "#    response = json.load(json_file)    #busy here\n",
    "    \n",
    "#with open( os.path.join( PATH, 'tests/test_files/testing_bug/32014R1141-input.xmi_outputPar_det.json')) as json_file:\n",
    "#    response = json.load(json_file)   #busy here\n",
    "    \n",
    "with open( os.path.join( PATH, 'tests/test_files/testing_bug/32019L2121-input.xmi_outputPar_det.json')) as json_file:\n",
    "    response = json.load(json_file)   #busy here\n",
    "    \n",
    "#with open( os.path.join( PATH, 'tests/test_files/testing_bug/32019L2121-input.xmi_outputRO_gpu_2.json')) as json_file:\n",
    "#    response = json.load(json_file)\n",
    "\n",
    "#32019L2121-input.xmi_outputRO_gpu_2\n",
    "    \n",
    "#with open(  os.path.join( PATH, 'tests/test_files/response_json_paragraph_annotations/doc_bf4ef384-bd7a-51c8-8f7d-d2f61865d767_response.json')) as json_file:\n",
    "#    response = json.load(json_file)\n",
    "    \n",
    "OUTPUT_PATH=os.path.join( PATH, \"tests/test_files/output_reporting_obligations/testing_bug3.html\" )\n",
    "    \n",
    "decoded_cas=base64.b64decode( response[ 'cas_content' ] ).decode( 'utf-8' )\n",
    "\n",
    "cas=load_cas_from_xmi( decoded_cas, typesystem=typesystem )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add list view\n"
     ]
    }
   ],
   "source": [
    "from src.transform import ListTransformer\n",
    "\n",
    "#from src.transform import get_other_lines, transform_lines, flatten_offsets\n",
    "\n",
    "#from src.utils import SeekableIterator\n",
    "\n",
    "OldSofaID = 'html2textView'\n",
    "NewSofaID = 'ListView'\n",
    "value_between_tagtype = \"com.crosslang.uimahtmltotext.uima.type.ValueBetweenTagType\"\n",
    "paragraph_type = \"de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Paragraph\"\n",
    "\n",
    "transformer = ListTransformer( cas )\n",
    "print( \"add list view\" )\n",
    "transformer.add_list_view( OldSofaID )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_string=open( \"test.txt\" ).read()\n",
    "#test=\"\\n\".join([\" \".join(test_string.split( \"\\n\" )[0].split(  )[:490])+\"|(10,10)\" , \" \".join(test_string.split( \"\\n\" )[0].split(  )[:20])+\"|(10,10)\" ])\n",
    "#transformer.cas.get_view( \"ListView\" ).sofa_string=test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get reporting obligations\n",
      "loading tokenizer en_core_web_sm\n",
      "ARGM[] ARGM-ADV therefore\n",
      "ARGM[] ARGM-ADV at least\n",
      "ARGS[for] ARG2 for members holding shares with voting rights and who voted against the approval of the draft terms\n",
      "ARGS[to] ARG1 to have the right to exit the company and receive cash compensation for their shares that is equivalent to the value of those shares\n",
      "ARGS[to] ARG1 to the operation\n",
      "Writing output to /notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations/tests/test_files/output_reporting_obligations/testing_bug3.html using /notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations/tests/test_files/templates/out.html.template as html template\n",
      "46.427661418914795\n"
     ]
    }
   ],
   "source": [
    "print( \"get reporting obligations\" )\n",
    "import time\n",
    "start=time.time()\n",
    "reporting_obligations_finder.process_sentences( cas, ListSofaID='ListView'  )\n",
    "reporting_obligations_finder.add_xml_to_cas( cas, TEMPLATE_PATH, ROSofaID='ReportingObligationsView' )\n",
    "reporting_obligations_finder.print_to_html(  TEMPLATE_PATH, OUTPUT_PATH  )\n",
    "end=time.time()\n",
    "print( end-start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence=\"This is a test sentence.\"\n",
    "bert_model = Predictor.from_path( BERT_PATH, cuda_device=1 )\n",
    "parsed_sentence=bert_model.predict(\n",
    "    sentence=input_sentence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'is',\n",
       "   'description': '[ARG1: This] [V: is] [ARG2: a test sentence] .',\n",
       "   'tags': ['B-ARG1', 'B-V', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}],\n",
       " 'words': ['This', 'is', 'a', 'test', 'sentence', '.']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'is',\n",
       "   'description': '[ARG1: This] [V: is] [ARG2: a test sentence] .',\n",
       "   'tags': ['B-ARG1', 'B-V', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'O']}],\n",
       " 'words': ['This', 'is', 'a', 'test', 'sentence', '.']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "\n",
    "tokenizer = SpacyWordSplitter(language=\"en_core_web_sm\", pos_tags=True)\n",
    "tokenized_sentence=tokenizer.split_words( input_sentence )\n",
    "bert_model.predict_tokenized( [str( word ) for word in tokenized_sentence] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( tokenized_sentence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allennlp.data.tokenizers.token.Token"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( tokenized_sentence[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str( tokenized_sentence[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "\n",
    "tokenizer = SpacyWordSplitter(language=\"en_core_web_sm\", pos_tags=True) \n",
    "len(tokenizer.split_words( test.split( \"\\n\" )[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( test_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sd\n"
     ]
    }
   ],
   "source": [
    "if (len( \"\")  > 2 or len( \"test test test test\".split()) > 2) :\n",
    "    print( \"sd\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( test_string.split( ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2551"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len( tokenizer.split_words( test_string ) )\n",
    "\n",
    "# self._tokenizer = SpacyWordSplitter(language='en_core_web_sm', pos_tags=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5183799266815186\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "try: \n",
    "    parsed_sentence=bert_model.predict(sentence=test[2] )\n",
    "except RuntimeError:\n",
    "    print( \"RunTimeError, could not parse \" )\n",
    "end=time.time()\n",
    "print( end-start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RuntimeError"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_long_paragraphs(text: str ) -> list:\n",
    "    \n",
    "    if len(text) > 500:\n",
    "        text = re.sub(r'([^❮❬‖❭❯]{500}(?:[^❮❬‖❭❯.]|[.][^❮❬‖❭❯ ])*[.]) (?=[A-Z])', r'\\1\\n', text, re.MULTILINE + re.UNICODE)\n",
    "    \n",
    "    break_lines = [line.strip() for line in text.split( \"\\n\" ) if line.strip()]\n",
    "\n",
    "    return break_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "broken=break_long_paragraphs( test[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a key element of possessing European legal status, European political parties and European political foundations should have European legal personality. The acquisition of European legal personality should be subjected to requirements and procedures to protect the interests of the Member State of the seat, of the applicant for European legal status ('the applicant') and of any third parties concerned. In particular, any pre-existing national legal personality should be converted into a European legal personality and any individual rights and obligations that have accrued to the former national legal entity should be transferred to the new European legal entity.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broken[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.548712491989136\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "bert_model.predict( sentence=test[2] )\n",
    "end=time.time()\n",
    "print( end-start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a key element of possessing European legal status, European political parties and European political foundations should have European legal personality. The acquisition of European legal personality should be subjected to requirements and procedures to protect the interests of the Member State of the seat, of the applicant for European legal status ('the applicant') and of any third parties concerned. In particular, any pre-existing national legal personality should be converted into a European legal personality and any individual rights and obligations that have accrued to the former national legal entity should be transferred to the new European legal entity. Moreover, in order to facil\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2][:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a key element of possessing European legal status, European political parties and European political foundations should have European legal personality. The acquisition of European legal personality should be subjected to requirements and procedures to protect the interests of the Member State of the seat, of the applicant for European legal status ('the applicant') and of any third parties concerned. In particular, any pre-existing national legal personality should be converted into a Europe\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test test and more. And more ❮ And then. And more and then. And more ❯ And more and then. And'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=open( \"test.txt\" ).read().split( \"\\n\" )\n",
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test test and more.',\n",
       " 'And more ❮ And then. And more and then.',\n",
       " 'And more ❯ And more and then.',\n",
       " 'And']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_long_paragraphs( test[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test test and more. And more ❮ And then. And more and then. And more❯ And more and then. And']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The termination of European legal personality should be subject to requirements and procedures to protect the interests of the Union, of the Member State of the seat, of the European political party or European political foundation and of any third parties concerned. In particular, if the European political party or European political foundation acquires legal personality under the law of the Member State of its seat, this should be considered as a conversion of the European legal personality and any individual rights and obligations that the former European legal entity has respectively acquired or incurred should be transferred to the national legal entity. Moreover, in order to facilitate continuity of activity, safeguards should be put in place to prevent the Member State concerned from applying prohibitive conditions to such conversion. If the European political party or European political foundation does not acquire legal personality in the Member State of its seat, it should be wound up in accordance with the law of that Member State and in accordance with the condition requiring it not to pursue profit goals. ❮ The Authority and the Authorising Officer of the European Parliament should be able to agree modalities with the Member State concerned regarding the termination of the European legal personality, in particular in order to ensure the recovery of funds received from the general budget of the European Union and any financial sanctions.❯ The termination of European legal personality should be subject to requirements and procedures to protect the interests of the Union, of the Member State of the seat, of the European political party or European political foundation and of any third parties concerned. In particular, if the European political party or European political foundation acquires legal personality under the law of the Member State of its seat, this should be considered as a conversion of the European legal personality and any individual rights and obligations that the former European legal entity has respectively acquired or incurred should be transferred to the national legal entity. Moreover, in order to facilitate continuity of activity, safeguards should be put in place to prevent the Member State concerned from applying prohibitive conditions to such conversion. If the European political party or European political foundation does not acquire legal personality in the Member State of its seat, it should be wound up in accordance with the law of that Member State and in accordance with the condition requiring it not to pursue profit goals']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"get reporting obligations\" )\n",
    "import time\n",
    "start=time.time()\n",
    "reporting_obligations_finder = ReportingObligationsFinder( cas, bert_model, nlp )\n",
    "reporting_obligations_finder.process_sentences( ListSofaID='ListView'  )\n",
    "reporting_obligations_finder.add_xml_to_cas( TEMPLATE_PATH, ROSofaID='ReportingObligationsView' )\n",
    "reporting_obligations_finder.print_to_html(  TEMPLATE_PATH, OUTPUT_PATH  )\n",
    "end=time.time()\n",
    "print( end-start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_long_paragraphs(text: str ) -> list:\n",
    "    \n",
    "    if len(text) > 10:\n",
    "        text = re.sub(r'([^❮❬‖❭❯]{10}(?:[^❮❬‖❭❯.]|[.][^❮❬‖❭❯ ])*[.]) (?=[A-Z])', r'\\1\\n', text, re.MULTILINE + re.UNICODE)\n",
    "    \n",
    "    break_lines = [line.strip() for line in text.split( \"\\n\" ) if line.strip()]\n",
    "\n",
    "    return break_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"As a key element of possessing European legal status, European political parties and European political foundations should have European legal personality.  ❮ Test and.  ❯ ❯ . The acquisition of European legal personality should be subject to requirements and procedures to protect the interests of the Member State of the seat, of the applicant for European legal status (the applicant) and of any third parties concerned. In particular, any pre-existing national legal personality should be converted into a European legal personality and any individual rights and obligations that have accrued to the former national legal entity should be transferred to the new European legal entity. Moreover, in order to facilitate continuity of activity, safeguards should be put in place to prevent the Member State concerned from applying prohibitive conditions to such conversion. The Member State of the seat should be able to specify which types of national legal persons may be converted into European legal persons, and to withhold its agreement to the acquisition of European legal personality under this Regulation until adequate guarantees are provided, in particular, for the legality of the applicant statutes under the laws of that Member State or for the protection of creditors or holders of other rights in respect of any pre-existing national legal personality.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As a key element of possessing European legal status, European political parties and European political foundations ❮ should have European legal personality.  ❮ Test and.  ❯ ❯ . The acquisition of European legal personality should be subject to requirements and procedures to protect the interests of the Member State of the seat, of the applicant for European legal status (the applicant) and of any third parties concerned.',\n",
       " 'In particular, any pre-existing national legal personality should be converted into a European legal personality and any individual rights and obligations that have accrued to the former national legal entity should be transferred to the new European legal entity.',\n",
       " 'Moreover, in order to facilitate continuity of activity, safeguards should be put in place to prevent the Member State concerned from applying prohibitive conditions to such conversion.',\n",
       " 'The Member State of the seat should be able to specify which types of national legal persons may be converted into European legal persons, and to withhold its agreement to the acquisition of European legal personality under this Regulation until adequate guarantees are provided, in particular, for the legality of the applicant statutes under the laws of that Member State or for the protection of creditors or holders of other rights in respect of any pre-existing national legal personality.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_long_paragraphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get reporting obligations\n",
      "processing sentence: 5. In the case of a sample, only a selection of the credit institutions and other institutions in the potential reporting population shall be asked to report. The variables that shall be estimated by means of the sample are the interest rates and the amounts of new business and the interest rates on outstanding amounts. They are referred to as sampling variables. In order to minimise the risk that the results of a sample survey deviate from the true (unknown) values in the potential reporting population, the sample shall be constructed in such a way that it is representative of the potential reporting population. For the purpose of MFI interest rate statistics a sample shall be considered representative if all the characteristics that are relevant for MFI interest rate statistics and inherent in the potential reporting population are also reflected in the sample. For drawing the initial sample, NCBs may use suitable proxies and models to produce the sampling scheme even if the underlying data, which are derived from existing sources, may not match perfectly the definitions of this Regulation.|(11667, 12776)5. In the case of a sample, only a selection of the credit institutions and other institutions in the potential reporting population shall be asked to report. The variables that shall be estimated by means of the sample are the interest rates and the amounts of new business and the interest rates on outstanding amounts. They are referred to as sampling variables. In order to minimise the risk that the results of a sample survey deviate from the true (unknown) values in the potential reporting population, the sample shall be constructed in such a way that it is representative of the potential reporting population. For the purpose of MFI interest rate statistics a sample shall be considered representative if all the characteristics that are relevant for MFI interest rate statistics and inherent in the potential reporting population are also reflected in the sample. For drawing the initial sample, NCBs may use suitable proxies and models to produce the sampling scheme even if the underlying data, which are derived from existing sources, may not match perfectly the definitions of this Regulation.|(11667, 12776)5. In the case of a sample, only a selection of the credit institutions and other institutions in the potential reporting population shall be asked to report. The variables that shall be estimated by means of the sample are the interest rates and the amounts of new business and the interest rates on outstanding amounts. They are referred to as sampling variables. In order to minimise the risk that the results of a sample survey deviate from the true (unknown) values in the potential reporting population, the sample shall be constructed in such a way that it is representative of the potential reporting population. For the purpose of MFI interest rate statistics a sample shall be considered representative if all the characteristics that are relevant for MFI interest rate statistics and inherent in the potential reporting population are also reflected in the sample. For drawing the initial sample, NCBs may use suitable proxies and models to produce the sampling scheme even if the underlying data, which are derived from existing sources, may not match perfectly the definitions of this Regulation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range: Tried to access index 512 out of table with 511 rows. at /opt/conda/conda-bld/pytorch_1579022030672/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7b8cbda7b8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreporting_obligations_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReportingObligationsFinder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreporting_obligations_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_sentences\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mListSofaID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ListView'\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mreporting_obligations_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_xml_to_cas\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mTEMPLATE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mROSofaID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ReportingObligationsView'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mreporting_obligations_finder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_to_html\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mTEMPLATE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations/src/reporting_obligations.py\u001b[0m in \u001b[0;36mprocess_sentences\u001b[0;34m(self, ListSofaID)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;31m#process the main_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mlist_xml_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;31m#set the offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations/src/reporting_obligations.py\u001b[0m in \u001b[0;36mprocess_sentence\u001b[0;34m(self, sentence, subsentence, main_sentence)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m#parse the sentence with ALLEN_NLP model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mparsed_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_sentence\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mverbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_data_to_relevant_verbs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mparsed_sentence\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations/src/reporting_obligations.py\u001b[0m in \u001b[0;36mparse_sentence\u001b[0;34m(self, input_sentence)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         parsed_sentence=self.bert_model.predict(\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/allennlp/predictors/semantic_role_labeler.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msemantic\u001b[0m \u001b[0mroles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_tokenized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_sentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/allennlp/predictors/semantic_role_labeler.py\u001b[0m in \u001b[0;36mpredict_json\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"verbs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"words\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/allennlp/predictors/semantic_role_labeler.py\u001b[0m in \u001b[0;36mpredict_instances\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_on_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"verbs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"words\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mforward_on_instances\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0minstance_separated_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/allennlp/models/srl_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, verb_indicator, metadata, tags)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                              \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverb_indicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                              \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                              output_all_encoded_layers=False)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0membedded_text_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mextended_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mwords_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range: Tried to access index 512 out of table with 511 rows. at /opt/conda/conda-bld/pytorch_1579022030672/work/aten/src/TH/generic/THTensorEvenMoreMath.cpp:418"
     ]
    }
   ],
   "source": [
    "print( \"get reporting obligations\" )\n",
    "import time\n",
    "start=time.time()\n",
    "reporting_obligations_finder = ReportingObligationsFinder( cas, bert_model, nlp )\n",
    "reporting_obligations_finder.process_sentences( ListSofaID='ListView'  )\n",
    "reporting_obligations_finder.add_xml_to_cas( TEMPLATE_PATH, ROSofaID='ReportingObligationsView' )\n",
    "reporting_obligations_finder.print_to_html(  TEMPLATE_PATH, OUTPUT_PATH  )\n",
    "end=time.time()\n",
    "print( end-start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.8721108436584473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( (test_text*3).split() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5. In the case of a sample, only a selection of the credit institutions and other institutions in the potential reporting population shall be asked to report. The variables that shall be estimated by means of the sample are the interest rates and the amounts of new business and the interest rates on outstanding amounts. They are referred to as sampling variables. In order to minimise the risk that the results of a sample survey deviate from the true (unknown) values in the potential reporting population, the sample shall be constructed in such a way that it is representative of the potential reporting population. For the purpose of MFI interest rate statistics a sample shall be considered representative if all the characteristics that are relevant for MFI interest rate statistics and inherent in the potential reporting population are also reflected in the sample. For drawing the initial sample, NCBs may use suitable proxies and models to produce the sampling scheme even if the underlying data, which are derived from existing sources, may not match perfectly the definitions of this Regulation.|(11667, 12776)'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1124"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"2.   The data shall contain at least the following elements ❮the identity and contact details of each contribution debtor as determined in accordance with Article 4 of Regulation (EU) No 1163/2014 for the purpose of the supervisory fees ‖ the fee factors determined in accordance with Article 10 of Regulation (EU) No 1163/2014 ‖ whether a contribution debtor is significant in accordance with Article 6(4) of Regulation (EU) No 1024/2013 or is an entity or group in relation to which the ECB has decided in accordance with Article 6(5)(b) of Regulation (EU) No 1024/2013 to exercise directly all of the relevant powers ‖ any data that the ECB has determined in the absence of reporting from a contribution debtor, in accordance with Article 10(5) of Regulation (EU) No 1163/2014 ‖ the validity date underlying the fee calculation of each contribution debtor determining the duration the contribution debtor was subject to the supervisory fee and any change of status in accordance with Article 7(2) of Regulation (EU) No 1163/2014 in the given fee period❯\"\n",
    "\n",
    "text = re.sub(r'([^❮❬‖❭❯]{10}(?:[^❮❬‖❭❯.]|[.][^❮❬‖❭❯ ])*[.]) (?=[A-Z])', r'\\1\\n', text, re.MULTILINE + re.UNICODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.   The data shall contain at least the following elements ❮the identity and contact details of each contribution debtor as determined in accordance with Article 4 of Regulation (EU) No 1163/2014 for the purpose of the supervisory fees ‖ the fee factors determined in accordance with Article 10 of Regulation (EU) No 1163/2014 ‖ whether a contribution debtor is significant in accordance with Article 6(4) of Regulation (EU) No 1024/2013 or is an entity or group in relation to which the ECB has decided in accordance with Article 6(5)(b) of Regulation (EU) No 1024/2013 to exercise directly all of the relevant powers ‖ any data that the ECB has determined in the absence of reporting from a contribution debtor, in accordance with Article 10(5) of Regulation (EU) No 1163/2014 ‖ the validity date underlying the fee calculation of each contribution debtor determining the duration the contribution debtor was subject to the supervisory fee and any change of status in accordance with Article 7(2) of Regulation (EU) No 1163/2014 in the given fee period❯']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split( \"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check performance issue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'❮'=='❮'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_break_long_paragraphs(text):\n",
    "    if len(text) > 10:\n",
    "        text = re.sub(r'([^❮❬‖❭❯]{10}(?:[^❮❬‖❭❯.]|[.][^❮❬‖❭❯ ])*[.]) (?=[A-Z])', r'\\1\\n', text, re.MULTILINE + re.UNICODE)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.   The data shall contain at least the following elements ❮the identity and contact details of each contribution debtor as determined in accordance with Article 4 of Regulation (EU) No 1163/2014 for the purpose of the supervisory fees ‖ the fee factors determined in accordance with Article 10 of Regulation (EU) No 1163/2014 ‖ whether a contribution debtor is significant in accordance with Article 6(4) of Regulation (EU) No 1024/2013 or is an entity or group in relation to which the ECB has decided in accordance with Article 6(5)(b) of Regulation (EU) No 1024/2013 to exercise directly all of the relevant powers ‖ any data that the ECB has determined in the absence of reporting from a contribution debtor, in accordance with Article 10(5) of Regulation (EU) No 1163/2014 ‖ the validity date underlying the fee calculation of each contribution debtor determining the duration the contribution debtor was subject to the supervisory fee and any change of status in accordance with Article 7(2) of Regulation (EU) No 1163/2014 in the given fee period❯\n"
     ]
    }
   ],
   "source": [
    "print_break_long_paragraphs( text  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.transform import ListTransformer\n",
    "from src.reporting_obligations import ReportingObligationsFinder\n",
    "\n",
    "from src.transform import get_other_lines, transform_lines, flatten_offsets, postprocess_nested_lines\n",
    "\n",
    "from src.utils import SeekableIterator\n",
    "\n",
    "#print( f\"loading AllenNLP predictor from {BERT_PATH}\" )\n",
    "#bert_model = Predictor.from_path( BERT_PATH )\n",
    "\n",
    "#print( f\"loading spacy model from {SPACY_PATH}\" )\n",
    "#nlp=spacy.load( SPACY_PATH )\n",
    "\n",
    "OldSofaID = 'html2textView'\n",
    "NewSofaID = 'ListView'\n",
    "value_between_tagtype = \"com.crosslang.uimahtmltotext.uima.type.ValueBetweenTagType\"\n",
    "paragraph_type = \"de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Paragraph\"\n",
    "\n",
    "value_between_tagtype_generator=cas.get_view( OldSofaID ).select( value_between_tagtype )        \n",
    "\n",
    "#value_between_tagtype_generator=get_deepest_child_tags(  cas, OldSofaID , \\\n",
    "#                   value_between_tagtype=value_between_tagtype  )\n",
    "\n",
    "seek_vbtt=SeekableIterator( iter(value_between_tagtype_generator) )\n",
    "\n",
    "lines, offsets=get_other_lines( cas , OldSofaID, seek_vbtt, 'root', paragraph_type=paragraph_type )\n",
    "\n",
    "#flatten_offsets( offsets )\n",
    "\n",
    "#lines, offsets=postprocess_nested_lines( lines, offsets  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
