{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python  /notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations/process-article-lists.py  process-article-lists.py <yourfile>.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir( \"/notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations\" )\n",
    "\n",
    "!python process-article-lists.py process-article-lists.py.input.txt  > test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python extract-relation-info.py test.txt  > test1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir( \"/notebook/nas-trainings/arne/DGFISMA/reporting_obligations/code/DGFISMA_reporting_obligations\" )\n",
    "\n",
    "!python extract-relation-info.py test.txt > test1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import inspect\n",
    "\n",
    "#regexes to use:\n",
    "\n",
    "#subject detection:\n",
    "no_determiner_arg2_keywords = \"EBA|ESMA|ECB|EIF|EIB|EIOPA|ESRB|BIS|FSA|PRA|EIOPA|FSB|SRB|FMI|IRSG|OPSG|AMICE|(member )?state|(senior |upper |lower )?management|(office )?(staff|personnel)|(US |American )?(Senate|Congress)|someone|somebody\"\n",
    "singular_arg2_keywords = \"Commission|Institution|EBA|European|Parliament|Council|Senate|ESMA|ECB|EIF|EIB|EIOPA|ESRB|BIS|FSA|PRA|EIOPA|FSB|SRB|CCP|SFT|MMF|ETF|REIT|FMI|IORP|ODTI|G-SIB|G-SIFI|CMG|CSD|AIF|NCA|RCA|((competent|resolution||national|regional) )?authority|government|entity|(member )?state|(central )?bank|party|counterparty|(senior |upper |lower )?management|provider|originator|firm|seller|buyer|agent|lawyer|(control |audit(ing)? )unit|group|member( state)?|central body|head of (the )?[^ ]+|company|organization|organisation|committee|supervisor|personnel|staff|actuary|accountant|manager|person|lender|issuer|leader|customer|individual|association|team|corporation|enterprise|university|foundation|intermediary|insurer|borrower|depositor|(bond|policy)holder|liquidator|debtor|creditor|transferor|transferee|distributor|broker|custodian|client|investor|agency|subsidiary|(financial )?conglomerate|competitor\"\n",
    "plural_arg2_keywords = \"Commissions|Institutions|Parliaments|Councils|Senates|CCPs|SFTs|MMFs|ETFs|REITs|FMIs|IORPs|ODTIs||G-SIBs|G-SIFIs|CMGs|CSDs|AIFs|NCAs|RCAs|((competent|resolution|national|regional) )?authorities|governments|entities|(member )?states|(central )?banks|parties|counterparties|(senior |upper |lower )?managements|providers|originators|firms|sellers|buyers|agents|lawyers|(control |audit(ing)? )units|groups|members?( states)?|central bodies|heads of (the )?[^ ]+|companies|organizations|organisations|committees|supervisors||personnels|staffs|actuaries|accountants|managers|persons|people|lenders|issuers|leaders|customers|individuals|associations|teams|corporations|enterprises|universities|foundations|intermediaries|insurers|borrowers|depositors|(bond|policy)holders|liquidators|debtors|creditors|transferors|transferee|distributors|brokers|custodians|clients|investors|agencies|subsidiaries||(financial )?conglomerates|competitors\"\n",
    "all_arg2_keywords = singular_arg2_keywords + '|' + plural_arg2_keywords\n",
    "plural_or_nodet_arg2_keywords = plural_arg2_keywords + '|' + no_determiner_arg2_keywords\n",
    "\n",
    "#verbs and nouns related to obligations...:\n",
    "\n",
    "interesting_verbs = \"notify|notifies|notified|notifying|inform|informs|informed|informing|report|reports|reported|reporting|provide|provides|provided|providing|submit|submits|submitted|submitting|demonstrate|demonstrates|demonstrated|demonstrating|prove|proves|proved|proving|communicate|communicates|communicated|communicating|send|sends|sent|sending|issue|issues|issued|issuing|publish|publishes|published|publishing|state|disclose|discloses|disclosed|share|shares|shared|document|documents|documented|review|reviews|reviewed|monitor|monitors|monitored|audit|audits|audited|transmit|transmits|transmitted|collect|collects|collected|fill|fills|filled|analyze|analyzes|analyzed|analyse|analyses|analysed|assess|assesses|assessed|alert|alerts|alerted|gather|gathers|gathered|declare|declares|declared|file|files|filed|deliver|delivers|delivered|supply|supplies|supplied|record|records|recorded|maintain|maintains|maintained|record|recorded|compile|compiled\".split('|')\n",
    "obligation_verbs = \"report|reports|notify|notifies|inform|informs|send|sends|submits|disclose|discloses|alert|alerts\".split('|')\n",
    "interesting_nouns = \"review|audit|disclosure|report|documentation|plan|system|procedure|process|processes|analysis|analyses|assessment|evaluation|This material|This document\".split('|')\n",
    "obligation_nouns = \"review|audit|disclosure|report|documentation\".split('|')\n",
    "interesting_nouns_valid_verbs_direct = \"carry|carried|conduct|conducted|repeat|repeated|perform|performed|produce|produced|implement|implemented|prepare|prepared|subject|subjected|draw|drawn|write|written\".split('|')\n",
    "interesting_nouns_valid_verbs_subj = \"include|included|comprise|comprised|consist|consisted|address|addressed|support|supported|meet|met|specify|specified|capture|captured|incorporate|incorporated|contain|contained|enable|enabled|allow|allowed|make|made\".split('|')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than this  outside1\n",
      "❮ more inside1 more insdide2  ❯ more inside3  ❮ more inside1 more insdide2 ❯\n"
     ]
    }
   ],
   "source": [
    "input_sentence=\"more than this ❮ more inside1 more insdide2  ❯ more inside3  ❮ more inside1 more insdide2 ❯ outside1\"  \n",
    "\n",
    "input_sentence = input_sentence.rstrip('\\r\\n')\n",
    "input_sentence_following_data = re.sub(r'(^[^❮]+|[^❯]+$)',r'',input_sentence)  #finds everything between \" ❮ ❯ \"\n",
    "if len(input_sentence_following_data) > 0: input_sentence = input_sentence.replace(input_sentence_following_data, '', 1)\n",
    "\n",
    "print( input_sentence ) #the part outside the brackets\n",
    "print( input_sentence_following_data )  #this is what is inside the brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Storing of the current location (i.e. detection of sections):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['part one of this', '', '', '', '', '']\n",
      "['part one of this', '', 'chapter something chapter article', '', '', '']\n",
      "['part one of this', '', 'chapter something chapter article', 'section something', '', '']\n",
      "['part one', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "# store the current location in the file\n",
    "pending_location_types = [['part ','annex '],['title '],['chapter '],['section '],['sub-section '],['article ']]\n",
    "pending_location_names = list(map(lambda x: '', pending_location_types))\n",
    "def update_pending_location_names(input_sentence):\n",
    "    global last_known_subject\n",
    "    for i, loc_type_names in enumerate(pending_location_types):\n",
    "        for loc_type in loc_type_names:\n",
    "            if str(input_sentence[0:len(loc_type)]).lower() == loc_type:\n",
    "                for j in range(i,len(pending_location_names)):\n",
    "                    pending_location_names[j] = ''\n",
    "                pending_location_names[i] = input_sentence\n",
    "                last_known_subject = '' # reset last known subject every article\n",
    "\n",
    "input_sentences=[  'part one of this', 'chapter something chapter article', 'section something' , 'part one'    ] \n",
    "\n",
    "for input_sentence in input_sentences:\n",
    "\n",
    "    update_pending_location_names(input_sentence)\n",
    "\n",
    "    print(pending_location_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Update last known subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. something EBA must do something  : something EBA\n",
      "2. test test something EBA must do something  : EBA\n",
      "test test and the EBA shall something : EBA\n",
      "test test the EBA shall something : EBA\n",
      "and the EBA shall something : and the EBA\n",
      "2. EBA sdfds shall  : A sdfds\n",
      "2. EBa sdfds must  : \n",
      "2. a sdfds must  : this sdfds\n",
      "where something is : something\n",
      "and when something is : something\n",
      "\n",
      "\n",
      "2. something EBA must do something  : something EBA\n",
      "2. test test something EBA must do something  : EBA\n",
      "test test and the EBA shall something : EBA\n",
      "test test the EBA shall something : EBA\n",
      "and the EBA shall something : and the EBA\n",
      "2. EBA sdfds shall  : A sdfds\n",
      "2. EBa sdfds must  : A sdfds\n",
      "2. a sdfds must  : this sdfds\n",
      "where something is : something\n",
      "and when something is : something\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def looks_like_arg2(text:str,allow_them=True):\n",
    "    text_start = text[0:35]\n",
    "    if re.search(r'(?<!of the )(?<!of an )(?<!of a )\\b(' + all_arg2_keywords + r')\\b(?! ?\\'s)', text_start, re.I):\n",
    "        return True\n",
    "    if re.match(r'^([^ ]+ |at least )?(to |for )?(us|him|her|the others?)\\b', text_start, re.I):\n",
    "        return True\n",
    "    if allow_them and re.match(r'^([^ ]+ |at least )?(to |for )?(them)\\b', text_start, re.I):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def looks_like_arg0(text: str):\n",
    "    return looks_like_arg2(text, False) or text.lower() in 'they|it'.split('|')\n",
    "\n",
    "last_known_subject = ''\n",
    "def update_last_known_subject(input_sentence):\n",
    "    global last_known_subject\n",
    "    input_sentence = re.sub(r'^ *[0-9]*[.] *', r'', input_sentence)\n",
    "    input_sentence = re.sub(r'^ *\\([a-z0-9]*\\) *', r'', input_sentence)\n",
    "    # general \"when\" lookup\n",
    "    subj_match = re.search(r'(?i:(?:when|where|if|as soon as))(?: ?[,][^,.]+[,])? ((an?|the|this|that|their|its|one|two|three|any( such( an?)?)?|such( an?)?|all|every|each) ([^ ]+)( ([^ ]+ )?(?i:' + all_arg2_keywords + r'))?|([^ ]+ ){0,2}(?i:' + plural_or_nodet_arg2_keywords + r')|[A-Z][A-Z]+|([A-Z][a-z]+ )+)', input_sentence)\n",
    "    subj_match_str = str(subj_match.group(1)) if subj_match else ''\n",
    "    when_clause_subject = re.sub(r'^(an?|the|this|that|their|its|one|any( such( an?)?)?|such( an?)?) (?![A-Z][A-Z])', 'this ', subj_match_str, re.I).strip()\n",
    "    when_clause_subject = re.sub(r'^(an?|one|any( such( an?)?)?|such( an?)?) ', 'this ', when_clause_subject, re.I).strip()\n",
    "    if when_clause_subject and looks_like_arg0(when_clause_subject): \n",
    "        last_known_subject = when_clause_subject\n",
    "\n",
    "    if re.search(r'shall|may|must', input_sentence):\n",
    "        # shall lookup\n",
    "        subj_match = re.search(r'(?:^|(?=[A-Z])|, |‖ (?:and/or )?)((?i:(an?|the|this|that|their|its|one|two|three|any( such( an?)?)?|such( an?)?|all|every|each)) ([^ ]+)( ([^ ]+ )?(?i:' + all_arg2_keywords + r'))?|([^ ]+ ){0,2}(?i:' + plural_or_nodet_arg2_keywords + r')|[A-Z][A-Z]+|([A-Z][a-z]+ )+) (shall|may|must) ', input_sentence)\n",
    "        subj_match_str = str(subj_match.group(1)) if subj_match else ''\n",
    "        when_clause_subject = re.sub(r'^(an?|the|this|that|their|its|one|any( such( an?)?)?|such( an?)?) (?![A-Z][A-Z])', 'this ', subj_match_str, re.I).strip()\n",
    "        when_clause_subject = re.sub(r'^(an?|one|any( such( an?)?)?|such( an?)?) ', 'this ', when_clause_subject, re.I).strip()\n",
    "        if when_clause_subject and looks_like_arg0(when_clause_subject):\n",
    "            last_known_subject = when_clause_subject\n",
    "              \n",
    "#examples:\n",
    "\n",
    "input_sentences=[  \"2. something EBA must do something \" , \\\n",
    "                   \"2. test test something EBA must do something \" , \\\n",
    "                   \"test test and the EBA shall something\", \\\n",
    "                   \"test test the EBA shall something\", \\\n",
    "                   \"and the EBA shall something\" , \\\n",
    "                   \"2. EBA sdfds shall \", \\\n",
    "                   \"2. EBa sdfds must \", \\\n",
    "                   \"2. a sdfds must \",\\\n",
    "                   \"where something is\",\\\n",
    "                   \"and when something is\"\n",
    "                ]  \n",
    "\n",
    "for input_sentence in input_sentences:\n",
    "    last_known_subject=''\n",
    "    update_last_known_subject(input_sentence)\n",
    "    print(  input_sentence , \":\"  ,  last_known_subject )\n",
    "    \n",
    "print( \"\\n\" )\n",
    "\n",
    "last_known_subject=''    \n",
    "for input_sentence in input_sentences:\n",
    "    #last_known_subject=''\n",
    "    update_last_known_subject(input_sentence)\n",
    "    print(  input_sentence , \":\"  ,  last_known_subject )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Check part of process_sentence function using regexes (the part where convertion from where->when; have in place->maintain... etc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence_1_regexes(input_sentence):\n",
    "    #print('==========================================================')\n",
    "    #print(input_sentence)\n",
    "\n",
    "    # skip obvious definitions\n",
    "    \n",
    "    # detected definitions should be skipped... AD  (first do annotation of definition, next reporting obligation...)\n",
    "    \n",
    "    if '\" means ' in input_sentence: return\n",
    "    if '’ means ' in input_sentence: return\n",
    "\n",
    "    input_sentence = re.sub(r'^ *[0-9]*[.] *', r'', input_sentence)\n",
    "    input_sentence = re.sub(r'^ *\\([a-z0-9]*\\) *', r'', input_sentence)\n",
    "    input_sentence = re.sub(r' (?:keep|maintain) ([^,]+) (?:informed of |posted on |updated on ) ', r' continuously inform \\1 of ', input_sentence)\n",
    "    input_sentence = re.sub(r' (?:keep|maintain) ([^,]+) (?:informed|posted|updated)\\b ?', r' continuously inform \\1 ', input_sentence)\n",
    "    input_sentence = re.sub(r' (?:issue) ((?:a|the|its|their|this) certificate|(?:a|the|its|their|this) copy|(?:a|the|its|their|this) declaration|(?:a|the|its|their|this) directive|(?:a|the|its|their|this) draft|(?:a|the|its|their|this) final|(?:a|the|its|their|this) required|(?:a|the|its|their|this) memorendum|(?:a|the|its|their|this) contract|(?:a|the|its|their|this) new|(?:a|the|its|their|this) notice|(?:a|the|its|their|this) policy|(?:a|the|its|their|this) public statement|(?:a|the|its|their|this) report|(?:a|the|its|their|this) revised|(?:a|the|its|their|this) supplementary|(?:a|the|its|their|this) warning|(?:an|the|its|their|this) additional|(?:an|the|its|their|this) annual|(?:an|the|its|their|this) official|(?:an|the|its|their|this) order|(?:new |additional |supplementary|revised |official|draft |final |annual )?directives|(?:new |additional |supplementary|revised |official|draft |final |annual )?guidance|(?:new |additional |supplementary|revised |official|draft |final |annual )?guidelines|(?:new |additional |supplementary|revised |official|draft |final |annual )?recommendations|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulation rules|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulations|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulatory guidelines|the following)\\b ?', r' publish \\1 ', input_sentence)\n",
    "    input_sentence = re.sub(r' (?:issues) ((?:a|the|its|their|this) certificate|(?:a|the|its|their|this) copy|(?:a|the|its|their|this) declaration|(?:a|the|its|their|this) directive|(?:a|the|its|their|this) draft|(?:a|the|its|their|this) final|(?:a|the|its|their|this) required|(?:a|the|its|their|this) memorendum|(?:a|the|its|their|this) contract|(?:a|the|its|their|this) new|(?:a|the|its|their|this) notice|(?:a|the|its|their|this) policy|(?:a|the|its|their|this) public statement|(?:a|the|its|their|this) report|(?:a|the|its|their|this) revised|(?:a|the|its|their|this) supplementary|(?:a|the|its|their|this) warning|(?:an|the|its|their|this) additional|(?:an|the|its|their|this) annual|(?:an|the|its|their|this) official|(?:an|the|its|their|this) order|(?:new |additional |supplementary|revised |official|draft |final |annual )?directives|(?:new |additional |supplementary|revised |official|draft |final |annual )?guidance|(?:new |additional |supplementary|revised |official|draft |final |annual )?guidelines|(?:new |additional |supplementary|revised |official|draft |final |annual )?recommendations|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulation rules|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulations|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulatory guidelines|the following)\\b ?', r' publishes \\1 ', input_sentence)\n",
    "    input_sentence = re.sub(r' (?:issued) ((?:a|the|its|their|this) certificate|(?:a|the|its|their|this) copy|(?:a|the|its|their|this) declaration|(?:a|the|its|their|this) directive|(?:a|the|its|their|this) draft|(?:a|the|its|their|this) final|(?:a|the|its|their|this) required|(?:a|the|its|their|this) memorendum|(?:a|the|its|their|this) contract|(?:a|the|its|their|this) new|(?:a|the|its|their|this) notice|(?:a|the|its|their|this) policy|(?:a|the|its|their|this) public statement|(?:a|the|its|their|this) report|(?:a|the|its|their|this) revised|(?:a|the|its|their|this) supplementary|(?:a|the|its|their|this) warning|(?:an|the|its|their|this) additional|(?:an|the|its|their|this) annual|(?:an|the|its|their|this) official|(?:an|the|its|their|this) order|(?:new |additional |supplementary|revised |official|draft |final |annual )?directives|(?:new |additional |supplementary|revised |official|draft |final |annual )?guidance|(?:new |additional |supplementary|revised |official|draft |final |annual )?guidelines|(?:new |additional |supplementary|revised |official|draft |final |annual )?recommendations|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulation rules|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulations|(?:new |additional |supplementary|revised |official|draft |final |annual )?regulatory guidelines|the following)\\b ?', r' published \\1 ', input_sentence)\n",
    "    \n",
    "    # input_sentence = re.sub(r'(?<!(?: that | which | who | if it | if they )) (?:is|are) required to ', r' must ', input_sentence)\n",
    "    input_sentence = re.sub(r' (?:is|are) required to ', r' must ', input_sentence)\n",
    "    input_sentence = re.sub(r' shall be required to ', r' shall, as required, ', input_sentence)\n",
    "    input_sentence = re.sub(r' and be required to ', r' and, as required, ', input_sentence)\n",
    "    input_sentence = re.sub(r' (?:is|are) able to ', r' can ', input_sentence)\n",
    "    input_sentence = re.sub(r' shall be able to ', r' shall, if needed, ', input_sentence)\n",
    "    input_sentence = re.sub(r' and be able to ', r' and, if needed, ', input_sentence)\n",
    "    input_sentence = re.sub(r' (?:is|are) responsible for ', r' monitor ', input_sentence)\n",
    "    input_sentence = re.sub(r' shall be responsible for ', r' shall monitor ', input_sentence)\n",
    "    input_sentence = re.sub(r' and be responsible for ', r' and monitor ', input_sentence)\n",
    "    input_sentence = re.sub(r' subject to ', r' subjected to ', input_sentence)\n",
    "    input_sentence = re.sub(r'\\bThere shall be ', r'One shall implement ', input_sentence)\n",
    "    input_sentence = re.sub(r'\\bthere shall be ', r'one shall implement ', input_sentence)\n",
    "    input_sentence = re.sub(r' have in place ', r' maintain ', input_sentence)\n",
    "    input_sentence = re.sub(r' have( [^.;‖]{0,35})? in place ', r' maintain\\1 ', input_sentence)\n",
    "    input_sentence = re.sub(r' have( [^.;‖]{0,20})?(?= (systems|procedures?|policy|policies|process|processes|strategy|strategies|practice|practices|methodology|methodologies) )', r' maintain\\1 ', input_sentence)\n",
    "    input_sentence = re.sub(r' prior to ', r' before ', input_sentence)\n",
    "    input_sentence = re.sub(r' where, ', r' when, ', input_sentence)\n",
    "    input_sentence = re.sub(r' where ', r' when ', input_sentence)\n",
    "    input_sentence = re.sub(r'^where ', r'when ', input_sentence)\n",
    "    input_sentence = re.sub(r' Where, ', r' When, ', input_sentence)\n",
    "    input_sentence = re.sub(r' Where ', r' When ', input_sentence)\n",
    "    input_sentence = re.sub(r'^Where ', r'When ', input_sentence)\n",
    "    input_sentence = re.sub(r' prior to ', r' before ', input_sentence)\n",
    "    input_sentence = re.sub(r' Prior to ', r' Before ', input_sentence)\n",
    "    input_sentence = re.sub(r'^Prior to ', r'Before ', input_sentence)\n",
    "\n",
    "    # fast-skip sentences that cannot lead to a match\n",
    "    if not(False\n",
    "        or any((verb in input_sentence) for verb in interesting_verbs)\n",
    "        or any((noun in input_sentence) for noun in interesting_nouns)\n",
    "    ): return 'not an interesting sentence 1'\n",
    "\n",
    "    \n",
    "    #this code block does the same as the one above???\n",
    "    if not(False\n",
    "        or re.search(r'\\b(' + '|'.join(interesting_verbs) + r')\\b', input_sentence)\n",
    "        or re.search(r'\\b(' + '|'.join(interesting_nouns) + r')s?\\b', input_sentence)\n",
    "    ): return 'not an interesting sentence 2'\n",
    "    \n",
    "    return input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA shall review something where  : EBA shall review something when \n",
      "EBA shall do something where  : not an interesting sentence 1\n",
      "EBA ’ means review do something where  : None\n",
      "EBA report to : EBA report to\n"
     ]
    }
   ],
   "source": [
    "# convertion of where->when ; check if possibly a reporting obligation...\n",
    "\n",
    "input_sentences=['EBA shall review something where ' , 'EBA shall do something where ', 'EBA ’ means review do something where ', 'EBA report to'  ]\n",
    "for input_sentence in input_sentences:\n",
    "    print( input_sentence, \":\" , process_sentence_1_regexes( input_sentence ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Inference on ALLEN NLP's \"predictor\" BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'shall',\n",
       "   'description': 'EBA [V: shall] review something and they should notify this to the commision following',\n",
       "   'tags': ['O',\n",
       "    'B-V',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'review',\n",
       "   'description': '[ARG0: EBA] [ARGM-MOD: shall] [V: review] [ARG1: something] and they should notify this to the commision following',\n",
       "   'tags': ['B-ARG0',\n",
       "    'B-ARGM-MOD',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'should',\n",
       "   'description': 'EBA shall review something and they [V: should] notify this to the commision following',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  {'verb': 'notify',\n",
       "   'description': 'EBA shall review something and [ARG0: they] [ARGM-MOD: should] [V: notify] [ARG1: this] [ARG2: to the commision following]',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG0',\n",
       "    'B-ARGM-MOD',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'B-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2']},\n",
       "  {'verb': 'following',\n",
       "   'description': 'EBA shall review something and they should notify this to [ARG1: the commision] [V: following]',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'B-V']}],\n",
       " 'words': ['EBA',\n",
       "  'shall',\n",
       "  'review',\n",
       "  'something',\n",
       "  'and',\n",
       "  'they',\n",
       "  'should',\n",
       "  'notify',\n",
       "  'this',\n",
       "  'to',\n",
       "  'the',\n",
       "  'commision',\n",
       "  'following']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "srl = Predictor.from_path(\"../code/DGFISMA_reporting_obligations/bert-base-srl-2019.06.17.tar.gz\")\n",
    "\n",
    "input_sentences=[ 'EBA shall review something and they should notify this to the commision following'  ]\n",
    "\n",
    "#input_sentences=[ 'EBA shall review something and they should notify this to the commision following ❮ EBA shall review something and they should notify this to the commision and  ❯'  ]\n",
    "\n",
    "\n",
    "for input_sentence in input_sentences:\n",
    "\n",
    "    input_sentence_following_data = re.sub(r'(^[^❮]+|[^❯]+$)',r'',input_sentence)  #finds everything between \" ❮ ❯ \"\n",
    "    if len(input_sentence_following_data) > 0: input_sentence = input_sentence.replace(input_sentence_following_data, '', 1)  #remove everything inside \" ❮ ❯ \" from the string\n",
    "\n",
    "#for input_sentence in input_sentences:\n",
    "    data = srl.predict(\n",
    "        sentence=input_sentence\n",
    "    )\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EBA shall review something and they should notify this to the commision following\n"
     ]
    }
   ],
   "source": [
    "print(input_sentence_following_data)\n",
    "print(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verb': 'shall', 'description': 'EBA [V: shall] review something and they should notify this to the commision following', 'tags': ['O', 'B-V', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n",
      "{'verb': 'review', 'description': '[ARG0: EBA] [ARGM-MOD: shall] [V: review] [ARG1: something] and they should notify this to the commision following', 'tags': ['B-ARG0', 'B-ARGM-MOD', 'B-V', 'B-ARG1', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n",
      "{'verb': 'should', 'description': 'EBA shall review something and they [V: should] notify this to the commision following', 'tags': ['O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'O', 'O', 'O', 'O', 'O', 'O']}\n",
      "{'verb': 'notify', 'description': 'EBA shall review something and [ARG0: they] [ARGM-MOD: should] [V: notify] [ARG1: this] [ARG2: to the commision following]', 'tags': ['O', 'O', 'O', 'O', 'O', 'B-ARG0', 'B-ARGM-MOD', 'B-V', 'B-ARG1', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2']}\n",
      "{'verb': 'following', 'description': 'EBA shall review something and they should notify this to [ARG1: the commision] [V: following]', 'tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARG1', 'I-ARG1', 'B-V']}\n"
     ]
    }
   ],
   "source": [
    "for verb_data in data['verbs']:\n",
    "    print( verb_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) Iterate over the found verbs, and check if the detected verb is a relevant verb, i.e. something like (notify ,  notifies, inform informs, etc. If not, skip this 'verb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data to relevant verbs, and apply rules to fix the output\n",
    "\n",
    "def filter_data_to_relevant_verbs( data ):\n",
    "\n",
    "    #keep track of detected relevant and irrelevant verbs (added by AD, for debugging purposes):\n",
    "    verbs=[]\n",
    "\n",
    "    for verb_data in data['verbs']:\n",
    "\n",
    "        # filter the data to relevant usages of those verbs\n",
    "        is_relevant_case=False\n",
    "\n",
    "        verb = verb_data['verb']\n",
    "        srl_output = str(verb_data['description'])\n",
    "\n",
    "        # do not go further if we don't have a verb (or if the verb is shall)\n",
    "        if verb == '' or verb == 'shall': \n",
    "            #print( verb,  \":\", \"verb is shall or missing\" )\n",
    "            verbs.append( (verb_data , is_relevant_case )  )\n",
    "            continue\n",
    "\n",
    "\n",
    "        # (filter for verbs)\n",
    "        verb_pos = srl_output.index(\"[V:\") if \"[V:\" in srl_output else 0\n",
    "        is_relevant_case = (is_relevant_case or (False\n",
    "            or (verb in obligation_verbs)\n",
    "            or (verb in interesting_verbs and (False\n",
    "                or (\"[ARGM-MOD:\" in srl_output and not('[ARGM-MOD: may' in srl_output))\n",
    "                or (\" shall \" in srl_output[max(0,verb_pos-50):verb_pos] and not(\" shall include \" in srl_output[max(0,verb_pos-50):verb_pos]) and \"[ARG0: \" in srl_output and \"[ARG1: \" in srl_output)\n",
    "            ))\n",
    "        ))\n",
    "\n",
    "        # TODO\n",
    "\n",
    "        # (filter for nouns)\n",
    "        is_relevant_case_based_on_verb = is_relevant_case\n",
    "        is_forgiving_noun_verb = True #verb == 'include' or verb == 'included' or verb == 'consist' or verb == 'consisted' or verb == 'comprise' or verb == 'comprised' or verb in forgiving_noun_verbs\n",
    "        is_relevant_case = (is_relevant_case or (True\n",
    "            and (verb != 'assigned') # just found it caused errors, and I don't see why this could be useful\n",
    "            and (\"[ARGM-MOD:\" in srl_output and not('[ARGM-MOD: may' in srl_output))\n",
    "            and (False\n",
    "                or (True\n",
    "                    and verb in interesting_nouns_valid_verbs_subj\n",
    "                    and re.search(r'\\[ARG[0-9]: [^\\]]*\\b(' + '|'.join(interesting_nouns) + r')s?\\b', srl_output)\n",
    "                )\n",
    "                or (True\n",
    "                    and verb in interesting_nouns_valid_verbs_direct\n",
    "                    and re.search(r'\\[ARG[1-9]: [^\\]]*\\b(' + '|'.join(interesting_nouns if is_forgiving_noun_verb else obligation_nouns) + r')s?\\b', srl_output)\n",
    "                )\n",
    "            )\n",
    "            and (verb != 'comply' or not(\" following \" in srl_output))\n",
    "        ))\n",
    "\n",
    "        verbs.append( ( verb_data, is_relevant_case_based_on_verb , is_relevant_case  )  )\n",
    "\n",
    "        #print( verb  , \"( is it a relevant case):\",  is_relevant_case )\n",
    "\n",
    "    return verbs\n",
    "#if not a relevant case ==> continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'verb': 'shall',\n",
       "   'description': 'EBA [V: shall] review something and they should notify this to the commision following',\n",
       "   'tags': ['O',\n",
       "    'B-V',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  False),\n",
       " ({'verb': 'review',\n",
       "   'description': '[ARG0: EBA] [ARGM-MOD: shall] [V: review] [ARG1: something] and they should notify this to the commision following',\n",
       "   'tags': ['B-ARG0',\n",
       "    'B-ARGM-MOD',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  True,\n",
       "  True),\n",
       " ({'verb': 'should',\n",
       "   'description': 'EBA shall review something and they [V: should] notify this to the commision following',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O']},\n",
       "  False,\n",
       "  False),\n",
       " ({'verb': 'notify',\n",
       "   'description': 'EBA shall review something and [ARG0: they] [ARGM-MOD: should] [V: notify] [ARG1: this] [ARG2: to the commision following]',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG0',\n",
       "    'B-ARGM-MOD',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'B-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2',\n",
       "    'I-ARG2']},\n",
       "  True,\n",
       "  True),\n",
       " ({'verb': 'following',\n",
       "   'description': 'EBA shall review something and they should notify this to [ARG1: the commision] [V: following]',\n",
       "   'tags': ['O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'B-V']},\n",
       "  False,\n",
       "  False)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = filter_data_to_relevant_verbs( data )\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#srl_output = str(verbs[0]['description'])\n",
    "\n",
    "#pick the third verb in this example:\n",
    "#i=3\n",
    "#srl_output = str( verbs[i][0]['description'] )  #only process the relevant cases...  ( i.e., check the flag \"is_relevant_case\" )\n",
    "#verb=verbs[i][0]['verb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7) flush pending location names (i.e.: write sentences like \"part\", \"section\" to html ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_pending_location_names():\n",
    "    for i, loc_name in enumerate(pending_location_names):\n",
    "        if len(loc_name) > 0: outfile.write('<h' + str(i+1) + '>' + loc_name + '</h' + str(i+1) + '>\\r\\n')\n",
    "        pending_location_names[i] = ''\n",
    "\n",
    "#flush_pending_location_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef match_class(span, reg): \\n    return re.search(reg, span.getAttribute(\\'class\\'))\\ndef match_class_in_list(span, list): \\n    return span.getAttribute(\\'class\\') in list\\ndef text_of(element):\\n    return str(element.firstChild.data)\\n\\ndef update_class(arg, new_class):\\n    arg_class = arg.getAttribute(\\'class\\')\\n    if arg_class != new_class:\\n        #print(\">\"+new_class+\":\" + arg.toxml())\\n        arg.setAttribute(\\'class\\', new_class)\\n        last_frame = inspect.getouterframes(inspect.currentframe())[1]\\n        last_frame_str = last_frame.filename + \\':\\' + str(last_frame.lineno)\\n        arg.setAttribute(\\'data-update-stack\\', last_frame_str)\\n\\n# fix particular verb constructions\\nargs = list(filter(lambda s: match_class(s, r\\'^(ARG[12]|ARGM-ADV|ARGM-MNR)$\\'), srl_dom_output.getElementsByTagName(\"span\")))\\nargs_pred = list(map(lambda arg: re.sub(\\n    r\\'^(?:only |at least )?(?:(about|of|to|on|for|with|in|that|where|when|if) )?(?:.*)$\\' if match_class(arg, r\\'^(ARG[12])$\\') else r\\'^(?:only |at least )?(?:(about|of|to|on|for|with) )?(?:.*)$\\', \\n    r\\'ARGS[\\x01]\\' if match_class(arg, r\\'^(ARG[12])$\\') else r\\'ARGM[\\x01]\\', \\n    text_of(arg), re.I), args))\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#helper functions:\n",
    "'''\n",
    "def match_class(span, reg): \n",
    "    return re.search(reg, span.getAttribute('class'))\n",
    "def match_class_in_list(span, list): \n",
    "    return span.getAttribute('class') in list\n",
    "def text_of(element):\n",
    "    return str(element.firstChild.data)\n",
    "\n",
    "def update_class(arg, new_class):\n",
    "    arg_class = arg.getAttribute('class')\n",
    "    if arg_class != new_class:\n",
    "        #print(\">\"+new_class+\":\" + arg.toxml())\n",
    "        arg.setAttribute('class', new_class)\n",
    "        last_frame = inspect.getouterframes(inspect.currentframe())[1]\n",
    "        last_frame_str = last_frame.filename + ':' + str(last_frame.lineno)\n",
    "        arg.setAttribute('data-update-stack', last_frame_str)\n",
    "\n",
    "# fix particular verb constructions\n",
    "args = list(filter(lambda s: match_class(s, r'^(ARG[12]|ARGM-ADV|ARGM-MNR)$'), srl_dom_output.getElementsByTagName(\"span\")))\n",
    "args_pred = list(map(lambda arg: re.sub(\n",
    "    r'^(?:only |at least )?(?:(about|of|to|on|for|with|in|that|where|when|if) )?(?:.*)$' if match_class(arg, r'^(ARG[12])$') else r'^(?:only |at least )?(?:(about|of|to|on|for|with) )?(?:.*)$', \n",
    "    r'ARGS[\\1]' if match_class(arg, r'^(ARG[12])$') else r'ARGM[\\1]', \n",
    "    text_of(arg), re.I), args))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_class_in_list(span, list): \n",
    "    return span.getAttribute('class') in list\n",
    "\n",
    "def text_of(element):\n",
    "    return str(element.firstChild.data)\n",
    "\n",
    "def convert_to_xml_and_fix_tags_hand_crafted( verb_tuple  ):\n",
    "    \n",
    "    from xml.dom.minidom import parseString\n",
    "\n",
    "    #helper functions:\n",
    "    def match_class(span, reg): \n",
    "        return re.search(reg, span.getAttribute('class'))\n",
    "    \n",
    "    def update_class(arg, new_class):\n",
    "        arg_class = arg.getAttribute('class')\n",
    "        if arg_class != new_class:\n",
    "            #print(\">\"+new_class+\":\" + arg.toxml())\n",
    "            arg.setAttribute('class', new_class)\n",
    "            last_frame = inspect.getouterframes(inspect.currentframe())[1]\n",
    "            last_frame_str = last_frame.filename + ':' + str(last_frame.lineno)\n",
    "            arg.setAttribute('data-update-stack', last_frame_str)\n",
    "            #print(\">\"+last_frame_str)\n",
    "    \n",
    "    srl_output = str( verb_tuple[0]['description'] )  #only process the relevant cases...  ( i.e., check the flag \"is_relevant_case\" )\n",
    "    verb=verb_tuple[0]['verb']\n",
    "    is_relevant_case_based_on_verb=verb_tuple[1]\n",
    "    \n",
    "    #Add html tags to srl_output:\n",
    "    \n",
    "    srl_html_output = srl_output\n",
    "    srl_html_output = re.sub(r'>', r'&gt;', srl_html_output)\n",
    "    srl_html_output = re.sub(r'<', r'&lt;', srl_html_output)\n",
    "    srl_html_output = re.sub(r'\\[([a-zA-Z0-9]+[^\\[\\]:]*)\\]', r'\\1', srl_html_output) # fix a weird bug where a span has no tag, for some reason\n",
    "    srl_html_output = re.sub(r'\\[([^ ]+): ', r'<span class=\"\\1\">', srl_html_output)\n",
    "    srl_html_output = re.sub(r'\\]', r'</span>', srl_html_output)\n",
    "    '''\n",
    "    next line adds context to the input sentence, it replaces <span class=\"ARG2\">to the commision following ... </span> with \n",
    "    <span class=\"ARG2\">to the commision following ... < input_sentence_following_data  >  </span> .\n",
    "    As it complicates integration with UIMA, and because it seems to be added only for visual purposes (this part is not parsed), we should probably remove the next line...\n",
    "    '''\n",
    "    if len(input_sentence_following_data) > 0: srl_html_output = re.sub(r'(<span[^>]*>[^<]* following\\b[^<]*)(</span>)', lambda m: m.group(1)+' '+input_sentence_following_data+m.group(2), srl_html_output)\n",
    "    srl_html_output = re.sub(r'<span[^>]+>([,.;])</span>', r'\\1', srl_html_output)\n",
    "    srl_html_output = re.sub(r'( ?[,.;])</span>', r'</span>\\1', srl_html_output)\n",
    "    srl_html_output = re.sub(r'(?<=[a-z][a-z][a-z])( ?[)])</span>', r'</span>\\1', srl_html_output)\n",
    "    srl_html_output = re.sub(r'(\\([^<>]*?)</span> \\)', r'\\1 )</span>', srl_html_output)\n",
    "    srl_html_output = '<p>' + srl_html_output + '</p>'\n",
    "\n",
    "    try:\n",
    "        srl_dom_output = parseString(srl_html_output)\n",
    "    except:\n",
    "        raise ValueError(srl_html_output)\n",
    "    \n",
    "    \n",
    "    # fix particular verb constructions\n",
    "    args = list(filter(lambda s: match_class(s, r'^(ARG[12]|ARGM-ADV|ARGM-MNR)$'), srl_dom_output.getElementsByTagName(\"span\")))\n",
    "    args_pred = list(map(lambda arg: re.sub(\n",
    "        r'^(?:only |at least )?(?:(about|of|to|on|for|with|in|that|where|when|if) )?(?:.*)$' if match_class(arg, r'^(ARG[12])$') else r'^(?:only |at least )?(?:(about|of|to|on|for|with) )?(?:.*)$', \n",
    "        r'ARGS[\\1]' if match_class(arg, r'^(ARG[12])$') else r'ARGM[\\1]', \n",
    "        text_of(arg), re.I), args))\n",
    "\n",
    "    #print(srl_output)\n",
    "    #print(\" \".join(args_pred))\n",
    "\n",
    "    # get some metadata\n",
    "    verb_is_provide = re.match(r'^(provide|provides|provided|providing)$', verb)\n",
    "    verb_is_notify = re.match(r'^(notify|notifies|notifying|notified)$', verb)\n",
    "    verb_is_inform = re.match(r'^(inform|informs|informing|informed)$', verb)\n",
    "    verb_is_demonstrate = re.match(r'^(demonstrate|demonstrates|demonstrating|demonstrated)$', verb)\n",
    "    verb_is_analyze = re.match(r'^(analyze[sd]?|analyse[sd]?|analy[zs]ing)$', verb)\n",
    "    verb_is_include = re.match(r'^(include|includes|included)$', verb)\n",
    "    verb_is_consist = re.match(r'^(consist(|s|ed)|comprise(|s|d)|incorporate(|s|d))$', verb)\n",
    "    #verb_is_be = re.match(r'^(be|been|is|are|was|were|being|become|becomes|became|becoming)$', verb)\n",
    "\n",
    "    # fix big but frequent argument-class mistakes\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARG1,ARG2'.split(',')):\n",
    "            if re.search(r'^(on the basis of )', text_of(arg), re.I):\n",
    "                update_class(arg, 'ARGM-MNR')\n",
    "            elif re.match(r'^(into account)', text_of(arg), re.I):\n",
    "                update_class(arg, 'ARGM-MNR')\n",
    "\n",
    "\n",
    "    # now let's fix \"provide with\"\n",
    "    if (verb_is_provide) and (('ARGS[with]' in args_pred) or ('ARGM[with]' in args_pred)):\n",
    "        for i, arg in enumerate(args):\n",
    "            arg_pred = args_pred[i]\n",
    "            arg_class = arg.getAttribute('class')\n",
    "            if arg_pred[0:4] == 'ARGS' and arg_pred != 'ARGS[with]' and looks_like_arg2(text_of(arg)):\n",
    "                update_class(arg,\"ARG2\")\n",
    "            elif arg_pred[4:] == '[with]':\n",
    "                update_class(arg,\"ARG1\")\n",
    "\n",
    "    # now let's fix \"notify something to someone\"\n",
    "    elif (verb_is_notify or verb_is_provide or verb_is_demonstrate) and (('ARGS[to]' in args_pred) or ('ARGM[to]' in args_pred)):\n",
    "        for i, arg in enumerate(args):\n",
    "            arg_pred = args_pred[i]\n",
    "            arg_class = arg.getAttribute('class')\n",
    "            print(arg_pred, arg_class, text_of(arg))\n",
    "            if arg_class == 'ARG1' and (arg_pred == 'ARGS[to]' or looks_like_arg2(text_of(arg),allow_them=False)):\n",
    "                update_class(arg, 'ARG2')\n",
    "            elif arg_class == 'ARG2' and arg_pred != 'ARGS[to]' and not(looks_like_arg2(text_of(arg),allow_them=False)):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_pred == 'ARGM[to]' and looks_like_arg2(text_of(arg)):\n",
    "                update_class(arg, 'ARG2')\n",
    "            elif arg_pred == 'ARGS[that]':\n",
    "                update_class(arg, 'ARG1')\n",
    "\n",
    "    # now let's fix \"notify someone of something\"\n",
    "    elif (verb_is_notify or verb_is_inform) and (('ARGS[about]' in args_pred ) or ('ARGM[about]' in args_pred) or ('ARGS[of]' in args_pred) or ('ARGM[of]' in args_pred)  or ('ARGS[on]' in args_pred)  or ('ARGM[on]' in args_pred) or ('ARGS[that]' in args_pred)):\n",
    "        did_remap_1_to_2 = False\n",
    "        for i, arg in enumerate(args):\n",
    "            arg_pred = args_pred[i]\n",
    "            arg_class = arg.getAttribute('class')\n",
    "            if arg_class == 'ARG1':\n",
    "                if arg_pred[4:] != '[that]':\n",
    "                    did_remap_1_to_2 = True\n",
    "                    update_class(arg, 'ARG2')\n",
    "            elif arg_pred[4:] == '[about]':\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_pred[4:] == '[that]' and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_pred[4:] == '[of]' and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_pred == 'ARGS[on]' and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_class == 'ARG2' and did_remap_1_to_2 and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "    elif (verb_is_notify or verb_is_inform):\n",
    "        for i, arg in enumerate(args):\n",
    "            arg_pred = args_pred[i]\n",
    "            arg_class = arg.getAttribute('class')\n",
    "            if arg_class == 'ARG1' and (looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG2')\n",
    "            elif arg_pred[4:] == '[about]' and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_pred[4:] == '[that]' and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_pred[4:] == '[of]' and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_pred == 'ARGS[on]' and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif arg_pred == 'ARGS[with]' and not(looks_like_arg2(text_of(arg))):\n",
    "                update_class(arg, 'ARG1')\n",
    "            elif re.match(r'^whether ', text_of(arg)):\n",
    "                update_class(arg, 'ARG1')\n",
    "    elif (verb_is_analyze):\n",
    "        for i, arg in enumerate(args):\n",
    "            arg_pred = args_pred[i]\n",
    "            arg_class = arg.getAttribute('class')\n",
    "            if arg_class == 'ARG2':\n",
    "                update_class(arg, 'ARG3')\n",
    "    elif (verb_is_include):\n",
    "        for i, arg in enumerate(args):\n",
    "            arg_pred = args_pred[i]\n",
    "            arg_class = arg.getAttribute('class')\n",
    "            if arg_class == 'ARG2':\n",
    "                update_class(arg, 'ARG0')\n",
    "    elif (verb_is_consist):\n",
    "        for i, arg in enumerate(args):\n",
    "            arg_pred = args_pred[i]\n",
    "            arg_class = arg.getAttribute('class')\n",
    "            if arg_class == 'ARG2':\n",
    "                update_class(arg, 'ARG1')\n",
    "            if arg_class == 'ARG1':\n",
    "                update_class(arg, 'ARG0')\n",
    "\n",
    "    # now let's fix \"when requested / when asked / upon request\" not being considered a time argument\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARGM-MNR,ARGM-ADV,ARGM-CAU,ARGM-LOC,ARGM-PRD'.split(',')):\n",
    "            if re.search(r'\\b(when(ever)? requested|when(ever?) asked|(up)?on (the )?request|if requested|on demand|in cases? of|in the ([^ ]+ )?cases?|on( at least)? an? ((semi|bi|tri) ?-? ?)?((annual|monthly|quarterly|daily|regular|frequent|scheduled|ongoing) )basis|continuously|constantly|regularly|promptly|thereafter|(after|before) [^ ]ing)\\b', text_of(arg), re.I):\n",
    "                update_class(arg, 'ARGM-TMP')\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARG2,ARG3'.split(',')):\n",
    "            if re.search(r'\\b(when(ever)? requested|when(ever?) asked|(up)?on (the )?request|if requested|on demand|in cases? of|in the ([^ ]+ )?cases?|on( at least)? an? ((semi|bi|tri) ?-? ?)?((annual|monthly|quarterly|daily|regular|frequent|scheduled|ongoing) )basis|continuously|constantly|regularly|promptly|thereafter|(after|before) [^ ]ing)\\b', text_of(arg), re.I):\n",
    "                update_class(arg, 'ARGM-TMP')\n",
    "\n",
    "    # now let's fix \"of the following\" not being considered a complement to C1 argument\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARGM-MNR,ARGM-ADV,ARGM-CAU,ARGM-LOC,ARGM-PRD,ARG2'.split(',')):\n",
    "            if match_class_in_list(arg,'ARG2') and looks_like_arg2(text_of(arg)): continue\n",
    "            if re.search(r'\\b(the following)\\b', text_of(arg), re.I):\n",
    "                if re.search(r'^([^ ]+ )?(in the following ways?|by using|based on|on the basis of)\\b', text_of(arg), re.I):\n",
    "                    update_class(arg, 'ARGM-MNR')\n",
    "                elif re.search(r'^([^ ]+ )?(when(ever)?|where|if)\\b', text_of(arg), re.I):\n",
    "                    update_class(arg, 'ARGM-TMP')\n",
    "                else:  \n",
    "                    update_class(arg, 'C-ARG1')\n",
    "            else:\n",
    "                if re.search(r'^(only |at least )?(by using|based on|on the basis of)\\b', text_of(arg), re.I):\n",
    "                    update_class(arg, 'ARGM-MNR')\n",
    "\n",
    "\n",
    "    # now let's fix \"when/if\" not being considered a time/condition argument\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARGM-ADV,ARGM-LOC'.split(',')):\n",
    "            if re.search(r'^([^ ]+ )?(when(ever)?|where|if)\\b', text_of(arg), re.I):\n",
    "                update_class(arg, 'ARGM-TMP')\n",
    "\n",
    "    # now let's fix \"publicized to the masses\" where \"to the masses\" is a ARGM-GOL\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARGM-GOL'.split(',')):\n",
    "            if looks_like_arg2(text_of(arg)):\n",
    "                update_class(arg, 'ARG2')\n",
    "            else:\n",
    "                update_class(arg, 'ARGM-TMP')\n",
    "    # transform into ARGM-MNR any \"for each\" block\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARG1,ARG2'.split(',')):\n",
    "            if (True\n",
    "                and (re.match(\"for (each|all|every)\\b\", text_of(arg)))\n",
    "            ):\n",
    "                update_class(arg, 'ARGM-MNR')\n",
    "    # transform ARG2 into ARG3 if it's \"subject to\"\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARG2'.split(',')):\n",
    "            if (True\n",
    "                and not(is_relevant_case_based_on_verb)\n",
    "                and not(looks_like_arg2(text_of(arg)))\n",
    "                and (not(verb in interesting_verbs) or re.match(\"subject to\", text_of(arg)))\n",
    "            ):\n",
    "                update_class(arg, 'ARG3')\n",
    "    # transform ARG0 into ARG3 if it's not an institution\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARG0'.split(',')):\n",
    "            if (True\n",
    "                and not(is_relevant_case_based_on_verb)\n",
    "                and not(looks_like_arg0(text_of(arg)))\n",
    "            ):\n",
    "                update_class(arg, 'ARG3')\n",
    "    # enable has a special ARG2->ARG0\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARG2'.split(',')):\n",
    "            if (True\n",
    "                and (verb == 'enable' or verb == 'enabled')\n",
    "            ):\n",
    "                update_class(arg, 'ARG0')\n",
    "    # special rule for ARG3 that actually look like an institution\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARG3'.split(',')):\n",
    "            if (True\n",
    "                and ((text_of(arg)[0:3] == 'to ') or (text_of(arg)[0:4] == 'for '))\n",
    "                and (looks_like_arg2(text_of(arg)))\n",
    "            ):\n",
    "                update_class(arg, 'ARG2')\n",
    "                \n",
    "    return srl_dom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'verb': 'notify',\n",
       "  'description': 'EBA shall review something and [ARG0: they] [ARGM-MOD: should] [V: notify] [ARG1: this] [ARG2: to the commision following]',\n",
       "  'tags': ['O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'O',\n",
       "   'B-ARG0',\n",
       "   'B-ARGM-MOD',\n",
       "   'B-V',\n",
       "   'B-ARG1',\n",
       "   'B-ARG2',\n",
       "   'I-ARG2',\n",
       "   'I-ARG2',\n",
       "   'I-ARG2']},\n",
       " True,\n",
       " True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=3\n",
    "verbs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARGS[] ARG1 this\n",
      "ARGS[to] ARG2 to the commision following\n"
     ]
    }
   ],
   "source": [
    "#should iterate over all verbs that are relevant. \n",
    "if verbs[i][2]==True:  #check if it is relevant case..\n",
    "    srl_dom_output=convert_to_xml_and_fix_tags_hand_crafted( verbs[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p data-frequency-class=\"1\" data-frequency-could-be-1=\"true\" data-frequency-could-be-2=\"false\" data-frequency-could-be-3=\"false\" data-frequency-might-be-1=\"true\" data-frequency-might-be-2=\"false\" data-frequency-might-be-3=\"false\" data-frequency-split=\"0.9668162524700166|0.032977092638611795|0.00020664681360358376\">EBA shall review something and <span class=\"ARG0\">they</span> <span class=\"ARGM-MOD\">should</span> <span class=\"V\">notify</span> <span class=\"ARG2\" data-update-stack=\"&lt;ipython-input-16-5bcd4da2db09&gt;:96\">this</span> <span class=\"ARG2\">to the commision following</span></p>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_dom_output.lastChild.toxml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>EBA shall review something and <span class=\"ARG0\">they</span> <span class=\"ARGM-MOD\">should</span> <span class=\"V\">notify</span> <span class=\"ARG2\" data-update-stack=\"&lt;ipython-input-29-5bcd4da2db09&gt;:96\">this</span> <span class=\"ARG2\">to the commision following ❮ EBA shall review something and they should notify this to the commision and  ❯</span></p>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_dom_output.lastChild.toxml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8) Predict frequency reporting obligation (using Spacy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp stuff (with spacy)\n",
    "# load the spacy frequency model\n",
    "import spacy\n",
    "nlp = spacy.load(\"../code/DGFISMA_reporting_obligations/spacy-textcat\" )\n",
    "# deduce obligation frequency from full paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_obligation_frequency( input_sentence, verb_tuple ,srl_dom_output  ):\n",
    "        \n",
    "    verb=verb_tuple[0]['verb']  #probably could get this from srl_dom_output, same for \"input sentence\" \n",
    "\n",
    "    # deduce obligation frequency from full paragraph\n",
    "    paragraph_frequence_predictions = nlp(input_sentence)\n",
    "\n",
    "    # decude obligation frequence from analyzed sentence\n",
    "    sentence_frequence_predictions = nlp(' '.join(map(lambda arg: text_of(arg), srl_dom_output.getElementsByTagName(\"span\"))))\n",
    "\n",
    "    # deduce obligation frequency from simplified sentence\n",
    "    argmtmp_sentence = \"they shall report it\"\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARGM-TMP'.split(',')):\n",
    "            argmtmp_sentence += ', ' + text_of(arg)\n",
    "    argmtmp_sentence += '.'\n",
    "    argmtmp_frequence_predictions = nlp(argmtmp_sentence) if \",\" in argmtmp_sentence else sentence_frequence_predictions\n",
    "\n",
    "    par_pred_balance = 0.45\n",
    "    sen_pred_balance = 0.25 \n",
    "    cat1_pred = par_pred_balance * paragraph_frequence_predictions.cats['1'] + sen_pred_balance * sentence_frequence_predictions.cats['1'] + (1.0-par_pred_balance-sen_pred_balance) * argmtmp_frequence_predictions.cats['1']\n",
    "    cat2_pred = par_pred_balance * paragraph_frequence_predictions.cats['2'] + sen_pred_balance * sentence_frequence_predictions.cats['2'] + (1.0-par_pred_balance-sen_pred_balance) * argmtmp_frequence_predictions.cats['2']\n",
    "    cat3_pred = par_pred_balance * paragraph_frequence_predictions.cats['3'] + sen_pred_balance * sentence_frequence_predictions.cats['3'] + (1.0-par_pred_balance-sen_pred_balance) * argmtmp_frequence_predictions.cats['3']\n",
    "\n",
    "    # apply corrective actions for by-dates\n",
    "    if re.search(r'[Bb](y|efore)(no later than )?( the)? [0-9]+ (January|February|March|April|May|June|July|August|September|October|November|December) [0-9][0-9][0-9]+', argmtmp_sentence):\n",
    "        cat1_pred = 0.35 + 0.65 * cat1_pred\n",
    "        cat2_pred = 0.65 * cat2_pred\n",
    "        cat3_pred = 0.65 * cat3_pred\n",
    "\n",
    "    # apply corrective actions depending on verb (collect, gather, maintain, monitor)\n",
    "    if verb in \"collect|gather|maintain|monitor|maintained|monitored\":\n",
    "        cat3_pred = 0.35 + 0.65 * cat3_pred\n",
    "        cat2_pred = 0.65 * cat2_pred + 0.35 * cat1_pred\n",
    "        cat1_pred = 0.30 * cat1_pred\n",
    "\n",
    "    # apply corrective actions for obvious demand-based requests\n",
    "    if re.search(r'\\b(upon request|when requested|on demand|when asked|as needed|when required)\\b', argmtmp_sentence, re.I):\n",
    "        cat2_pred = 0.25 + 0.75 * cat2_pred\n",
    "        cat1_pred = 0.75 * cat1_pred\n",
    "        cat3_pred = 0.75 * cat3_pred\n",
    "\n",
    "    best_cat = max([1,2,3], key=lambda i: [cat1_pred,cat2_pred,cat3_pred][i-1])\n",
    "    \n",
    "    srl_dom_output.lastChild.setAttribute('data-frequency-split', str(cat1_pred)+'|'+str(cat2_pred)+'|'+str(cat3_pred))\n",
    "    srl_dom_output.lastChild.setAttribute('data-frequency-class', str(best_cat))\n",
    "    srl_dom_output.lastChild.setAttribute('data-frequency-could-be-3', 'true' if cat3_pred > 0.35 else 'false')\n",
    "    srl_dom_output.lastChild.setAttribute('data-frequency-could-be-2', 'true' if cat2_pred > 0.35 else 'false')\n",
    "    srl_dom_output.lastChild.setAttribute('data-frequency-could-be-1', 'true' if cat1_pred > 0.35 else 'false')\n",
    "    srl_dom_output.lastChild.setAttribute('data-frequency-might-be-3', 'true' if cat3_pred > 0.15 else 'false')\n",
    "    srl_dom_output.lastChild.setAttribute('data-frequency-might-be-2', 'true' if cat2_pred > 0.15 else 'false')\n",
    "    srl_dom_output.lastChild.setAttribute('data-frequency-might-be-1', 'true' if cat1_pred > 0.15 else 'false')\n",
    "    \n",
    "    return srl_dom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p data-frequency-class=\"1\" data-frequency-could-be-1=\"true\" data-frequency-could-be-2=\"false\" data-frequency-could-be-3=\"false\" data-frequency-might-be-1=\"true\" data-frequency-might-be-2=\"false\" data-frequency-might-be-3=\"false\" data-frequency-split=\"0.9668162524700166|0.032977092638611795|0.00020664681360358376\">EBA shall review something and <span class=\"ARG0\">they</span> <span class=\"ARGM-MOD\">should</span> <span class=\"V\">notify</span> <span class=\"ARG2\" data-update-stack=\"&lt;ipython-input-16-5bcd4da2db09&gt;:96\">this</span> <span class=\"ARG2\">to the commision following</span></p>\n"
     ]
    }
   ],
   "source": [
    "srl_dom_output=predict_obligation_frequency( input_sentence, verbs[i] ,srl_dom_output  )\n",
    "print( srl_dom_output.lastChild.toxml() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EBA shall review something and they should notify this to the commision following'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p data-frequency-class=\"1\" data-frequency-could-be-1=\"true\" data-frequency-could-be-2=\"false\" data-frequency-could-be-3=\"false\" data-frequency-might-be-1=\"true\" data-frequency-might-be-2=\"false\" data-frequency-might-be-3=\"false\" data-frequency-split=\"0.9900492817163469|0.009775796649046242|0.00017486593569628896\">EBA shall review something and <span class=\"ARG0\">they</span> <span class=\"ARGM-MOD\">should</span> <span class=\"V\">notify</span> <span class=\"ARG2\" data-update-stack=\"&lt;ipython-input-29-5bcd4da2db09&gt;:96\">this</span> <span class=\"ARG2\">to the commision following ❮ EBA shall review something and they should notify this to the commision and  ❯</span></p>\n"
     ]
    }
   ],
   "source": [
    "srl_dom_output=predict_obligation_frequency( input_sentence, verbs[i] ,srl_dom_output  )\n",
    "print( srl_dom_output.lastChild.toxml() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_reference_resolution(  srl_dom_output , last_known_subject ):\n",
    "    \n",
    "    # solve cases where we have a \"When\" clause\n",
    "    \n",
    "    when_clause = None\n",
    "    when_clause_uppercase = False\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARGM-TMP'.split(',')):\n",
    "            if re.match(r'^(when|where|if|as soon as) ',text_of(arg), re.IGNORECASE):\n",
    "                when_clause = text_of(arg)\n",
    "                when_clause_uppercase = when_clause[0].isupper() or (arg.previousSibling == None or arg.previousSibling.previousSibling == None)\n",
    "\n",
    "    when_clause_subject = ''\n",
    "    if when_clause:\n",
    "        subj_match = re.match(r'(?i:(?:when|where|if|as soon as))(?: ?[,][^,.]+[,])? ((an?|the|this|that|their|its|one|two|three|any( such( an?)?)?|such( an?)?|all|every|each) ([^ ]+)( ([^ ]+ )?(?i:' + all_arg2_keywords + r'))?|([^ ]+ ){0,2}(?i:' + plural_or_nodet_arg2_keywords + r')|[A-Z][A-Z]+|([A-Z][a-z]+ )+)', when_clause)\n",
    "        subj_match_str = subj_match.group(1) if subj_match else ''\n",
    "        when_clause_subject = re.sub(r'^(an?|the|this|that|their|its|one|any( such( an?)?)?|such( an?)?) (?![A-Z][A-Z])', 'this ', subj_match_str).strip()\n",
    "        when_clause_subject = re.sub(r'^(an?|one|any( such( an?)?)?|such( an?)?) ', 'this ', when_clause_subject).strip()\n",
    "\n",
    "    if when_clause_subject:\n",
    "        # when an institution does X, it shall report Y to Z.\n",
    "        for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "            if match_class_in_list(arg, 'ARG0'.split(',')):\n",
    "                if (False\n",
    "                    or text_of(arg).lower() == 'it'\n",
    "                    or text_of(arg).lower() == 'they'\n",
    "                ):\n",
    "                    if text_of(arg).lower() == 'they': when_clause_subject = re.sub(r'^this ', 'these ', when_clause_subject)\n",
    "                    arg.setAttribute('data-old-text', text_of(arg))\n",
    "                    arg.firstChild.data = when_clause_subject\n",
    "                else:\n",
    "                    old_text = arg.firstChild.data\n",
    "                    new_text = re.sub(r'^(its|their) ', when_clause_subject + \" 's \", text_of(arg))\n",
    "                    if old_text != new_text:\n",
    "                        arg.setAttribute('data-old-text', old_text)\n",
    "                        arg.firstChild.data = new_text\n",
    "\n",
    "    if when_clause:\n",
    "        # when something happens, it shall be reported to Z.\n",
    "        for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "            if match_class_in_list(arg, 'ARG1'.split(',')):\n",
    "                if (False\n",
    "                    or (text_of(arg).lower() == 'it' and (when_clause_uppercase or verb == 'reported'))\n",
    "                ):\n",
    "                    arg.setAttribute('data-old-text', text_of(arg))\n",
    "                    arg.firstChild.data = re.sub(r'^(?i:(if|when)) ', 'the fact that ', when_clause)\n",
    "                elif (False\n",
    "                    or (text_of(arg) == 'them' and when_clause_uppercase)\n",
    "                ):\n",
    "                    #TODO: find object of when clause, use that\n",
    "                    arg.setAttribute('TODO','true')\n",
    "                    \n",
    "    # last_known_subject co-reference resolution (for subjects, obviously)\n",
    "    if last_known_subject:\n",
    "        for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "            if match_class_in_list(arg, 'ARG0'.split(',')):\n",
    "                if (False\n",
    "                    or (text_of(arg).lower() == 'it')\n",
    "                    or (text_of(arg).lower() == 'they')\n",
    "                ):\n",
    "                    current_last_known_subject = last_known_subject\n",
    "                    if text_of(arg).lower() == 'they': current_last_known_subject = re.sub(r'^this ', 'these ', last_known_subject)\n",
    "                    arg.setAttribute('data-old-text', text_of(arg))\n",
    "                    arg.setAttribute('data-last-known-subject','true')\n",
    "                    arg.firstChild.data = current_last_known_subject\n",
    "\n",
    "    #TODO: broader co-reference resolution\n",
    "    for arg in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "        if match_class_in_list(arg, 'ARG0,ARG1,ARG2,ARG3'.split(',')):\n",
    "            if (False\n",
    "                or (text_of(arg).lower() == 'it')\n",
    "                or (text_of(arg).lower() == 'they')\n",
    "                or (text_of(arg).lower() == 'them')\n",
    "                or (text_of(arg).lower() == 'this')\n",
    "                or (text_of(arg).lower() == 'that')\n",
    "            ):\n",
    "                arg.setAttribute('TODO','true')\n",
    "                    \n",
    "    return srl_dom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_dom_output = co_reference_resolution( srl_dom_output , last_known_subject )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p data-frequency-class=\"1\" data-frequency-could-be-1=\"true\" data-frequency-could-be-2=\"false\" data-frequency-could-be-3=\"false\" data-frequency-might-be-1=\"true\" data-frequency-might-be-2=\"false\" data-frequency-might-be-3=\"false\" data-frequency-split=\"0.9900492817163469|0.009775796649046242|0.00017486593569628896\">EBA shall review something and <span class=\"ARG0\" data-last-known-subject=\"true\" data-old-text=\"they\">something</span> <span class=\"ARGM-MOD\">should</span> <span class=\"V\">notify</span> <span TODO=\"true\" class=\"ARG2\" data-update-stack=\"&lt;ipython-input-29-5bcd4da2db09&gt;:96\">this</span> <span class=\"ARG2\">to the commision following ❮ EBA shall review something and they should notify this to the commision and  ❯</span></p>\n"
     ]
    }
   ],
   "source": [
    "print( srl_dom_output.lastChild.toxml() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something should notify this to the commision following ❮ EBA shall review something and they should notify this to the commision and  ❯'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(map(lambda arg: text_of(arg), srl_dom_output.getElementsByTagName(\"span\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=''\n",
    "def print_hello(  ):\n",
    "    global test\n",
    "    test='something'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "they shall report it"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_frequence_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they should notify this to the commision'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_of(element):\n",
    "    return str(element.firstChild.data)\n",
    "\n",
    "' '.join(map(lambda arg: text_of(arg), srl_dom_output.getElementsByTagName(\"span\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they should notify this to the commision'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(map( text_of, srl_dom_output.getElementsByTagName(\"span\")) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARG0\n",
      "they\n",
      "ARGM-MOD\n",
      "should\n",
      "V\n",
      "notify\n",
      "ARG2\n",
      "this\n",
      "ARG2\n",
      "to the commision\n"
     ]
    }
   ],
   "source": [
    "for span in srl_dom_output.getElementsByTagName(\"span\"):\n",
    "    print( span.getAttribute( 'class' ))\n",
    "    print( text_of( span )  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides = slideshow.getElementsByTagName(\"slide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-54ab16cb2798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrl_dom_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"//span\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'xpath'"
     ]
    }
   ],
   "source": [
    "srl_dom_output.xpath( \"//span\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xml.dom.minidom.Document"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type( srl_dom_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.xpath('//span[@class=\"nobr\"]/a[@href=\"http://www.google.com/\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        # decude obligation frequence from analyzed sentence\n",
    "        sentence_frequence_predictions = nlp(' '.join(map(lambda arg: text_of(arg), srl_dom_output.getElementsByTagName(\"span\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "srl_dom_output = parseString(srl_html_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# helpers\n",
    "def text_of(element):\n",
    "    return str(element.firstChild.data)\n",
    "\n",
    "def match_class(span, reg): \n",
    "    return re.search(reg, span.getAttribute('class'))\n",
    "def match_class_in_list(span, list): \n",
    "    return span.getAttribute('class') in list\n",
    "\n",
    "\n",
    "# fix particular verb constructions\n",
    "args = list(filter(lambda s: match_class(s, r'^(ARG[12]|ARGM-ADV|ARGM-MNR)$'), srl_dom_output.getElementsByTagName(\"span\")))\n",
    "args_pred = list(map(lambda arg: re.sub(\n",
    "    r'^(?:only |at least )?(?:(about|of|to|on|for|with|in|that|where|when|if) )?(?:.*)$' if match_class(arg, r'^(ARG[12])$') else r'^(?:only |at least )?(?:(about|of|to|on|for|with) )?(?:.*)$', \n",
    "    r'ARGS[\\1]' if match_class(arg, r'^(ARG[12])$') else r'ARGM[\\1]', \n",
    "    text_of(arg), re.I), args))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ARG0: EBA] [ARGM-MOD: shall] [V: review] [ARG1: something]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA [V: shall] review something\n",
      "[ARG0: EBA] [ARGM-MOD: shall] [V: review] [ARG1: something]\n"
     ]
    }
   ],
   "source": [
    "for verb_data in data[ 'verbs' ]:\n",
    "    print( verb_data['description'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and 1==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'verb': 'shall',\n",
       "  'description': 'EBA [V: shall] review something',\n",
       "  'tags': ['O', 'B-V', 'O', 'O']},\n",
       " {'verb': 'review',\n",
       "  'description': '[ARG0: EBA] [ARGM-MOD: shall] [V: review] [ARG1: something]',\n",
       "  'tags': ['B-ARG0', 'B-ARGM-MOD', 'B-V', 'B-ARG1']}]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[ 'verbs' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'verb_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-9e7ad6dc8315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrl_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverb_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'verb_data' is not defined"
     ]
    }
   ],
   "source": [
    "srl_output = str(verb_data['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' something shall, as required, something Where'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence=' something shall be required to something Where'\n",
    "input_sentence = re.sub(r' shall be required to ', r' shall, as required, ', input_sentence)\n",
    "input_sentence = re.sub(r' Where ', r' When ', input_sentence)\n",
    "\n",
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fdsf When dsfdsf'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r' Where ', r' When ',  \"fdsf Where dsfdsf\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this sdfds'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_known_subject=''\n",
    "input_sentence=\"2. something somrtih EBA must \"\n",
    "input_sentence=\"2. a sdfds shall \"\n",
    "\n",
    "\n",
    "update_last_known_subject(input_sentence)\n",
    "\n",
    "last_known_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'more than this  outside1'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['part ', 'annex ']\n",
      "1\n",
      "['title ']\n",
      "2\n",
      "['chapter ']\n",
      "3\n",
      "['section ']\n",
      "4\n",
      "['sub-section ']\n",
      "5\n",
      "['article ']\n"
     ]
    }
   ],
   "source": [
    "for i, loc_type_names in enumerate( pending_location_types):\n",
    "    print(i)\n",
    "    print( loc_type_names )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pending_location_types = [['part ','annex '],['title '],['chapter '],['section '],['sub-section '],['article ']]\n",
    "pending_location_names = list(map(lambda x: '', pending_location_types))\n",
    "\n",
    "pending_location_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
